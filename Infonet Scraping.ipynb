{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Extraindo e Analisando Notícias da Infonet**\n","O presente notebook foi criado no intuito de auxiliar em uma tarefa de Web Scraping no âmbito do Laboratório Multiusuário de Informática e Documentação Linguística (LAMID/UFS).</br>\n","A tarefa em questão foi a coleta e análise de dados contidos nas notícias do site [Infonet](https://infonet.com.br/).</br>\n","> Os dados extraídos foram:\n","* Data da publicação;\n","* Título;\n","* Resumo;\n","* Autoria;\n","* Link;\n","* Texto da Notícia.\n"],"metadata":{"id":"NQ9nBOGRxYgw"}},{"cell_type":"markdown","source":["###**Montando o drive**\n","O notebook foi criado no ambiente do Google Colab, então para salvarmos os arquivos de saída, conectamos o ambiente de programação ao Google Drive."],"metadata":{"id":"DXJbFevvlepQ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"vugZtw_WcfeM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Extraindo os dados**"],"metadata":{"id":"e_oj3PZMv_Kw"}},{"cell_type":"markdown","source":["###**Importando as bibliotecas necessárias**"],"metadata":{"id":"Tw-JQd4dQf42"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CryR16XbxTYv"},"outputs":[],"source":["from urllib.request import urlopen\n","from bs4 import BeautifulSoup\n","import pandas as pd"]},{"cell_type":"markdown","source":["###**Criando funções de busca**\n","Aqui são definidas as funções para a extração de cada dado de interesse:\n","\n","*   **extraiData**: data de publicação da notícia;\n","*   **extraiTitulo**: título da notícia;\n","*   **extraiResumo**: resumo da notícia;\n","*   **extraiAutoria**: autoria registrada no código fonte da notícia;\n","*   **extraiLink**: link para a notícia completa;\n","*   **extraiTexto**: texto completo da notícia.\n","\n"],"metadata":{"id":"48wY2GrmQjyU"}},{"cell_type":"code","source":["def extraiData(noticia):\n","    data = noticia.find('span',{'class':'time'})\n","    return data.get_text()\n","\n","def extraiTitulo(noticia):\n","    titulo = noticia.find('a', {'class':'post-url post-title'})\n","    return titulo.get_text().strip()\n","\n","def extraiResumo(noticia):\n","    resumo = noticia.find('div', {'class':'post-summary'})\n","    return resumo.get_text().strip()\n","\n","def extraiAutoria(noticia):\n","    autoria = noticia.find('i', {'class':'post-author author'})\n","    return autoria.get_text().strip()\n","\n","def extraiLink(noticia):\n","    link = noticia.find('h2').find('a').attrs['href']\n","    return link\n","\n","def extraiTexto(link):\n","    html = urlopen(link)\n","    bs = BeautifulSoup(html.read(), 'html.parser')\n","    texto = bs.find('div', {'class':'entry-content clearfix single-post-content'})\n","    return texto.get_text().strip()"],"metadata":{"id":"tM9HH4FKHh5K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Extraindo e armazenando os dados**\n","Aqui vamos inserir o link da página que desejamos extrair os dados na variável `LINK`. </br>\n","> **Observação**: é importante lembrar que esse código foi desenvolvido para funcionar com links do site da [infonet](https://infonet.com.br/). Então, é necessário que seja realizada uma busca por algum termo específico na parte de \"pesquisa\" do site e que o link exibido seja copiado e colado na variável especificada (`LINK`).\n","\n","Além disso, iremos inserir o número de páginas que desejamos coletar as notícias (no site da Infonet são exibidas **10 notícias por página**). O código irá abrir o número de páginas definido na variável `NUMERO_DE_PAGINAS`, e executar as funções para extrair os elementos que precisamos.\n"],"metadata":{"id":"zvV7AbNpSyIs"}},{"cell_type":"code","source":["#Link de busca\n","LINK = 'https://infonet.com.br/'\n","\n","NUMERO_DE_PAGINAS = 10"],"metadata":{"id":"SyItDpPaif3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["colunas = ['Link', 'Data', 'Título', 'Resumo', 'Autor(a)', 'Texto da Notícia']\n","manchetes = []\n","\n","for i in range(1, NUMERO_DE_PAGINAS + 1):\n","    link = LINK.replace('https://infonet.com.br/', f'https://infonet.com.br/page/{i}/')\n","\n","    html = urlopen(link)\n","    bs = BeautifulSoup(html.read(), 'html.parser')\n","\n","    noticias = bs.findAll('article')\n","\n","    for noticia in noticias:\n","        link = extraiLink(noticia)\n","        manchetes.append([link, extraiData(noticia), extraiTitulo(noticia), extraiResumo(noticia), extraiAutoria(noticia), extraiTexto(link)])"],"metadata":{"id":"GEvP4BHeLMHA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Criando data frame**\n","Aqui, passamos como parâmetros os nomes das colunas que desejamos ver em nossa planilha (definidos na lista `colunas` na célula anterior) e os dados, que foram armazenados na lista `manchetes`.</br>Passados os parâmetros, o código irá organizar os dados em uma estrutura chamada _Data frame_.\n","</br>\n","> As linhas `df.head()` e `df.info()` exibem as primeiras linhas do dataframe e algumas informações, como o número de dados armazenados. Essas funções são interessantes para sabermos se os dados foram armazenados corretamente."],"metadata":{"id":"EONPZSfzAQO0"}},{"cell_type":"code","source":["df = pd.DataFrame(manchetes, columns = colunas)\n","\n","df.head()\n","df.info()"],"metadata":{"id":"p7SjnStdKJ81"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Salvando a planilha com os dados**\n","> **Planilha sem análise**</br>\n","\n","\n","Por fim, é interessante que os dados sejam salvos. Aqui iremos inserir o nome que queremos que nosso arquivo tenha na variável `NOME_ARQUIVO_DADOS` e rodar a célula para que a planilha seja salva."],"metadata":{"id":"0HaY7B0gBlY5"}},{"cell_type":"code","source":["NOME_ARQUIVO_DADOS = 'Dados Infonet'\n","\n","#Salvar em .xlsx (Excel)\n","planilhaDados = df.to_excel(f'{NOME_ARQUIVO_DADOS}.xlsx', encoding='UTF-8')\n","\n","#Salvar em .csv\n","#planilhaDados = df.to_csv(f'{NOME_ARQUIVO_DADOS}.csv', encoding='UTF-8')"],"metadata":{"id":"TVAQjVdvMzfu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Analisando os dados**"],"metadata":{"id":"3zBM2-Sova0R"}},{"cell_type":"markdown","source":["###**Instalando e importando as bibliotecas necessárias**"],"metadata":{"id":"k38usMEywqo0"}},{"cell_type":"code","source":["!pip install spacy\n","!python -m spacy download pt_core_news_lg\n","import spacy\n","import pandas as pd"],"metadata":{"id":"jMQ2Q_yuwqDW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Analisando a voz verbal nos títulos**\n","Definida a função `vozVerbal`, iremos aplicá-la nos títulos coletados. Como os dados já foram extraidos e estão no dataframe, podemos acessá-los inserindo apenas o nome da sua coluna correspondente, como foi feito chamando a coluna `df['Título']`.\n","\n","Em seguida, criamos uma nova coluna chamada **Análise de Voz Verbal** que aramzenará os títulos contendo as análises."],"metadata":{"id":"J1Za9vymx1dJ"}},{"cell_type":"code","source":["titulosAnalisados = []\n","\n","nlp = spacy.blank(\"pt\")\n","nlp = spacy.load(\"pt_core_news_lg\")\n","\n","for titulo in df['Título']:\n","    doc = nlp(titulo)\n","\n","    analiseVozVerbal = ''\n","    for token in doc:\n","        if str(token.pos_) == 'VERB':\n","            if 'Voice=Pass' in str(token.morph):\n","                analiseVozVerbal += ' ' + token.text + ' (Voz PASSIVA)'\n","            else:\n","                analiseVozVerbal += ' ' + token.text + ' (Voz ATIVA)'\n","        else:\n","            analiseVozVerbal += ' ' + token.text\n","\n","    titulosAnalisados.append(analiseVozVerbal)\n","\n","df['Análise de Voz Verbal'] = titulosAnalisados\n","\n","df.head()"],"metadata":{"id":"g1uBxhYtx6KO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Salvando a planilha com dados e análises**\n","> **Com análise**\n","\n","\n","A planilha seguir possui o acréscimo de uma última coluna contendo a análise de voz verbal dos títulos.\n"],"metadata":{"id":"-RXnN_tQx6t4"}},{"cell_type":"code","source":["NOME_ARQUIVO_ANALISE = '(Análise) Dados Infonet'\n","\n","#Salvar em .xlsx (Excel)\n","planilhaDados = df.to_excel(f'{NOME_ARQUIVO_ANALISE}.xlsx', encoding='UTF-8')\n","\n","#Salvar em .csv\n","#planilhaDados = df.to_csv(f'{NOME_ARQUIVO_ANALISE}.csv', encoding='UTF-8')"],"metadata":{"id":"4vh_bRzf-GUD"},"execution_count":null,"outputs":[]}]}